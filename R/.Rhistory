simulate_data <- function(r = 0.9, binary = F) {
# Input parameters
n_train <- 500
n_lab <- 500
n_unlab <- 5000
sigma_Y <- sqrt(5)
# Simulate the data
mu <- c(0, 0) # Mean vector
Sigma <- matrix(c(1, 0, 0, 1), 2, 2) # Covariance matrix
n_data <- n_unlab + n_lab + n_train
data <- as.data.frame(MASS::mvrnorm(n_data, mu, Sigma))
colnames(data) <- c("X1", "X2")
beta_1 <- beta_2 <- r * sigma_Y / sqrt(2 * 3)
data$epsilon <- rnorm(n_data, 0, sqrt(1 - r^2)) * sigma_Y
data$Y <- data$X1 * beta_1 + data$X2 * beta_2 + data$X1^2 * beta_1 + data$X2^2 * beta_1 + data$epsilon
if (binary) {
data$Y <- ifelse(data$Y > median(unlist(data$Y)), 1, 0)
# Split the data
train_data <- data[1:n_train, ]
lab_data <- data[(n_train + 1):(n_lab + n_train), ]
unlab_data <- data[(n_lab + n_train + 1):n_data, ]
# Fit the machine learning model
train_data$Y <- as.factor(train_data$Y)
train_fit <- randomForest::randomForest(Y ~ X1 + X2, data = train_data)
lab_data$Y_hat <- predict(train_fit, newdata = lab_data)
unlab_data$Y_hat <- predict(train_fit, newdata = unlab_data)
X_lab <- as.data.frame(lab_data$X1)
X_unlab <- as.data.frame(unlab_data$X1)
Y_lab <- as.data.frame(lab_data$Y)
Yhat_lab <- as.data.frame(as.numeric(lab_data$Y_hat) - 1)
Yhat_unlab <- as.data.frame(as.numeric(unlab_data$Y_hat) - 1)
colnames(X_lab) <- "X1"
colnames(X_unlab) <- "X1"
colnames(Y_lab) <- "Y"
colnames(Yhat_lab) <- "Y_hat"
colnames(Yhat_unlab) <- "Y_hat"
out <- list(X_lab = X_lab, X_unlab = X_unlab, Y_lab = Y_lab, Yhat_lab = Yhat_lab, Yhat_unlab = Yhat_unlab)
} else {
# Split the data
train_data <- data[1:n_train, ]
lab_data <- data[(n_train + 1):(n_lab + n_train), ]
unlab_data <- data[(n_lab + n_train + 1):n_data, ]
# Fit the machine learning model
train_fit <- randomForest::randomForest(Y ~ X1 + X2, data = train_data)
lab_data$Y_hat <- predict(train_fit, newdata = lab_data)
unlab_data$Y_hat <- predict(train_fit, newdata = unlab_data)
X_lab <- as.data.frame(lab_data$X1)
X_unlab <- as.data.frame(unlab_data$X1)
Y_lab <- as.data.frame(lab_data$Y)
Yhat_lab <- as.data.frame(lab_data$Y_hat)
Yhat_unlab <- as.data.frame(unlab_data$Y_hat)
colnames(X_lab) <- "X1"
colnames(X_unlab) <- "X1"
colnames(Y_lab) <- "Y"
colnames(Yhat_lab) <- "Y_hat"
colnames(Yhat_unlab) <- "Y_hat"
out <- list(X_lab = X_lab, X_unlab = X_unlab, Y_lab = Y_lab, Yhat_lab = as.numeric(Yhat_lab), Yhat_unlab = as.numeric(Yhat_unlab))
}
return(out)
}
simulate_data()
#----------------------------------------------#
# Simulate the data for testing the functions
#----------------------------------------------#
simulate_data <- function(r = 0.9, binary = F) {
# Input parameters
n_train <- 500
n_lab <- 500
n_unlab <- 5000
sigma_Y <- sqrt(5)
# Simulate the data
mu <- c(0, 0) # Mean vector
Sigma <- matrix(c(1, 0, 0, 1), 2, 2) # Covariance matrix
n_data <- n_unlab + n_lab + n_train
data <- as.data.frame(MASS::mvrnorm(n_data, mu, Sigma))
colnames(data) <- c("X1", "X2")
beta_1 <- beta_2 <- r * sigma_Y / sqrt(2 * 3)
data$epsilon <- rnorm(n_data, 0, sqrt(1 - r^2)) * sigma_Y
data$Y <- data$X1 * beta_1 + data$X2 * beta_2 + data$X1^2 * beta_1 + data$X2^2 * beta_1 + data$epsilon
if (binary) {
data$Y <- ifelse(data$Y > median(unlist(data$Y)), 1, 0)
# Split the data
train_data <- data[1:n_train, ]
lab_data <- data[(n_train + 1):(n_lab + n_train), ]
unlab_data <- data[(n_lab + n_train + 1):n_data, ]
# Fit the machine learning model
train_data$Y <- as.factor(train_data$Y)
train_fit <- randomForest::randomForest(Y ~ X1 + X2, data = train_data)
lab_data$Y_hat <- predict(train_fit, newdata = lab_data)
unlab_data$Y_hat <- predict(train_fit, newdata = unlab_data)
X_lab <- as.data.frame(lab_data$X1)
X_unlab <- as.data.frame(unlab_data$X1)
Y_lab <- as.data.frame(lab_data$Y)
Yhat_lab <- as.data.frame(as.numeric(lab_data$Y_hat) - 1)
Yhat_unlab <- as.data.frame(as.numeric(unlab_data$Y_hat) - 1)
colnames(X_lab) <- "X1"
colnames(X_unlab) <- "X1"
colnames(Y_lab) <- "Y"
colnames(Yhat_lab) <- "Y_hat"
colnames(Yhat_unlab) <- "Y_hat"
out <- list(X_lab = X_lab, X_unlab = X_unlab, Y_lab = Y_lab, Yhat_lab = Yhat_lab, Yhat_unlab = Yhat_unlab)
} else {
# Split the data
train_data <- data[1:n_train, ]
lab_data <- data[(n_train + 1):(n_lab + n_train), ]
unlab_data <- data[(n_lab + n_train + 1):n_data, ]
# Fit the machine learning model
train_fit <- randomForest::randomForest(Y ~ X1 + X2, data = train_data)
lab_data$Y_hat <- predict(train_fit, newdata = lab_data)
unlab_data$Y_hat <- predict(train_fit, newdata = unlab_data)
X_lab <- as.data.frame(lab_data$X1)
X_unlab <- as.data.frame(unlab_data$X1)
Y_lab <- as.data.frame(lab_data$Y)
Yhat_lab <- as.data.frame(lab_data$Y_hat)
Yhat_unlab <- as.data.frame(unlab_data$Y_hat)
colnames(X_lab) <- "X1"
colnames(X_unlab) <- "X1"
colnames(Y_lab) <- "Y"
colnames(Yhat_lab) <- "Y_hat"
colnames(Yhat_unlab) <- "Y_hat"
out <- list(X_lab = X_lab, X_unlab = X_unlab, Y_lab = Y_lab, Yhat_lab = Yhat_lab, Yhat_unlab = Yhat_unlab)
}
return(out)
}
simulate_data()
simulate_data(binary = T)
install.packages("pkgdown")
usethis::use_pkgdown()
